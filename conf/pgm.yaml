# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir: 'out-shakespeare-char'
eval_interval: 250 # keep frequent because we'll overfit
eval_iters: 200
log_interval: 10 # don't print too too often


wandb_log: False # override via command line if you like
wandb_project: 'shakespeare-char'
wandb_run_name: 'mini-gpt'
model_name: "test_pgm"

dataset: 'shakespeare_char'
gradient_accumulation_steps: 1
batch_size: 64
block_size: 256 # context of up to 256 previous characters

# baby GPT model :)
n_layer: 6
n_head: 6
n_embd: 384
dropout: 0.2

learning_rate: 1e-3 # with baby networks can afford to go a bit higher
max_iters: 100
lr_decay_iters: 100 # make equal to max_iters usually
min_lr: 1e-4 # learning_rate / 10 usually
beta2: 0.99 # make a bit bigger because number of tokens per iter is small

warmup_iters: 20 # not super necessary potentially

# on macbook also add
# device: 'cpu'  # run on cpu only
# compile: False # do not torch compile the model
# conf/config.yaml
# I/O
eval_only: false

bias: false

# adamw optimizer
weight_decay: 0.1
beta1: 0.9
grad_clip: 1.0

# lr decay
decay_lr: true

# system
device: cuda
dtype: auto  # auto|float32|bfloat16|float16
seed: 42

# parallelism
dp_size: 1
pp_size: 1
tp_size: 1
